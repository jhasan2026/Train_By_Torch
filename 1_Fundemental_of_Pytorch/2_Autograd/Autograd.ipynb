{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:38.659834Z",
     "start_time": "2025-04-23T09:14:14.720671Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "2764556ade550be3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# y = x**2",
   "id": "7d7a2dab6143fe97"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.108086Z",
     "start_time": "2025-04-23T09:14:38.659834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "x"
   ],
   "id": "5fa290e257073eae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.138302Z",
     "start_time": "2025-04-23T09:14:39.108086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = x**2\n",
    "y"
   ],
   "id": "96510ada818d4143",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.293552Z",
     "start_time": "2025-04-23T09:14:39.138302Z"
    }
   },
   "cell_type": "code",
   "source": "y.backward()",
   "id": "e16690f09d6ceb9e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.298697Z",
     "start_time": "2025-04-23T09:14:39.293552Z"
    }
   },
   "cell_type": "code",
   "source": "x.grad",
   "id": "eef85852ce45e305",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# y = x**2\n",
    "# z = sin(y)"
   ],
   "id": "4b7370917c0d5902"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.325231Z",
     "start_time": "2025-04-23T09:14:39.298697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor(5.47, requires_grad=True)\n",
    "x"
   ],
   "id": "167d9de4bb660fba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.4700, requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.406012Z",
     "start_time": "2025-04-23T09:14:39.325231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = x**2\n",
    "z = torch.sin(y)"
   ],
   "id": "b30998a5b92fa276",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.423366Z",
     "start_time": "2025-04-23T09:14:39.406012Z"
    }
   },
   "cell_type": "code",
   "source": "z.backward()",
   "id": "28f9a61863e62090",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.427780Z",
     "start_time": "2025-04-23T09:14:39.423366Z"
    }
   },
   "cell_type": "code",
   "source": "x.grad",
   "id": "2a80e21c769bb0ac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8281)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# y = x**2\n",
    "# z = sin(y)\n",
    "# u = e**z"
   ],
   "id": "6f5b215602f4a1d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.440314Z",
     "start_time": "2025-04-23T09:14:39.427780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor(5.47, requires_grad=True)\n",
    "y = x ** 2\n",
    "z = torch.sin(y)\n",
    "u = torch.exp(z)"
   ],
   "id": "4e2dbc4f80b9fc6b",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.444627Z",
     "start_time": "2025-04-23T09:14:39.440314Z"
    }
   },
   "cell_type": "code",
   "source": "u.backward()",
   "id": "48c2e538110ca3ce",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.450393Z",
     "start_time": "2025-04-23T09:14:39.444627Z"
    }
   },
   "cell_type": "code",
   "source": "x.grad",
   "id": "a4e0e837a940c2da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3055)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Perceptron Backpropagation",
   "id": "d57cb166b6051fe6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.454299Z",
     "start_time": "2025-04-23T09:14:39.450393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor(6.7)\n",
    "y_true = torch.tensor(0.0)"
   ],
   "id": "184ba6e236fb65f8",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.458994Z",
     "start_time": "2025-04-23T09:14:39.454299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "w = torch.tensor(1.0 ,requires_grad=True)\n",
    "b = torch.tensor(0.0 ,requires_grad=True)"
   ],
   "id": "7c3b9b2adc05d230",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.534671Z",
     "start_time": "2025-04-23T09:14:39.458994Z"
    }
   },
   "cell_type": "code",
   "source": "z = torch.dot(x.unsqueeze(0),w.unsqueeze(0)) + b.unsqueeze(0)",
   "id": "3ff212e0edd964f2",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.553921Z",
     "start_time": "2025-04-23T09:14:39.534671Z"
    }
   },
   "cell_type": "code",
   "source": "y_pred = torch.sigmoid(z)",
   "id": "d35daab2682cba09",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.557934Z",
     "start_time": "2025-04-23T09:14:39.553921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    ephcilon = 1e-8\n",
    "    y_pred = torch.clamp(y_pred, ephcilon , 1-ephcilon)\n",
    "    return -(y_true * torch.log(y_pred)) + (1-y_true) * torch.log(1 - y_pred)"
   ],
   "id": "ba82b43233035416",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.605551Z",
     "start_time": "2025-04-23T09:14:39.557934Z"
    }
   },
   "cell_type": "code",
   "source": "loss = binary_cross_entropy(y_true, y_pred)",
   "id": "5227da2a79055a9f",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.660347Z",
     "start_time": "2025-04-23T09:14:39.605551Z"
    }
   },
   "cell_type": "code",
   "source": "loss.backward()",
   "id": "744949a337f3e564",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.665618Z",
     "start_time": "2025-04-23T09:14:39.660347Z"
    }
   },
   "cell_type": "code",
   "source": "w.grad",
   "id": "5c6689e3cae2ec46",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6.6918)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.670770Z",
     "start_time": "2025-04-23T09:14:39.665618Z"
    }
   },
   "cell_type": "code",
   "source": "b.grad",
   "id": "d566f2997de74696",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.9988)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Multivariate Function (partial Derivative)",
   "id": "27b925dbd7aec04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.675242Z",
     "start_time": "2025-04-23T09:14:39.671774Z"
    }
   },
   "cell_type": "code",
   "source": "x = torch.tensor([1.0,2.0,3.0], requires_grad=True)",
   "id": "8f789a8376e152",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.716852Z",
     "start_time": "2025-04-23T09:14:39.675242Z"
    }
   },
   "cell_type": "code",
   "source": "y = (x**2).mean()",
   "id": "71a7dde1cde82503",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.743673Z",
     "start_time": "2025-04-23T09:14:39.716852Z"
    }
   },
   "cell_type": "code",
   "source": "y.backward()",
   "id": "a413ef7fe53bd20b",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.750163Z",
     "start_time": "2025-04-23T09:14:39.743673Z"
    }
   },
   "cell_type": "code",
   "source": "print(x.grad)",
   "id": "c732ed02f5df8156",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6667, 1.3333, 2.0000])\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MLP",
   "id": "4cd501e8d3f51e1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.755224Z",
     "start_time": "2025-04-23T09:14:39.750163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = torch.tensor([3.9, 90])\n",
    "y_true = torch.tensor(0.0)"
   ],
   "id": "5f9ec89cb2f2d8ba",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.761327Z",
     "start_time": "2025-04-23T09:14:39.755224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "W1 = torch.rand(2,2, requires_grad=True)\n",
    "b1 = torch.rand(2, requires_grad=True)"
   ],
   "id": "18fc2e876b1773b0",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.833311Z",
     "start_time": "2025-04-23T09:14:39.761327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "z1 = torch.matmul(X, W1) + b1\n",
    "z1"
   ],
   "id": "6aed7792e2c3800f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([79.9966, 78.2017], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.856590Z",
     "start_time": "2025-04-23T09:14:39.833311Z"
    }
   },
   "cell_type": "code",
   "source": "o1 = torch.relu(z1)",
   "id": "3b1c09ed25725d96",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.860254Z",
     "start_time": "2025-04-23T09:14:39.856590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "W2 = torch.rand(2,1, requires_grad=True)\n",
    "b2 = torch.rand(1, requires_grad=True)"
   ],
   "id": "8c666c6c7d4ee78a",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.864754Z",
     "start_time": "2025-04-23T09:14:39.860254Z"
    }
   },
   "cell_type": "code",
   "source": "z2 = torch.matmul(o1, W2) + b2",
   "id": "ed10e17e48a7df1b",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.869191Z",
     "start_time": "2025-04-23T09:14:39.864754Z"
    }
   },
   "cell_type": "code",
   "source": "o2 = torch.sigmoid(z2)",
   "id": "eff430b28a5cf236",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.875074Z",
     "start_time": "2025-04-23T09:14:39.869191Z"
    }
   },
   "cell_type": "code",
   "source": "o2",
   "id": "9724a98415fb1a68",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.879482Z",
     "start_time": "2025-04-23T09:14:39.875074Z"
    }
   },
   "cell_type": "code",
   "source": "loss = binary_cross_entropy(y_true, o2)",
   "id": "36ccacaf064355",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.920836Z",
     "start_time": "2025-04-23T09:14:39.879482Z"
    }
   },
   "cell_type": "code",
   "source": "loss.backward()",
   "id": "df9586a4163a1ff0",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.964276Z",
     "start_time": "2025-04-23T09:14:39.920836Z"
    }
   },
   "cell_type": "code",
   "source": "W1.grad",
   "id": "4adc3e1c2c692aba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan],\n",
       "        [nan, nan]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:14:39.969186Z",
     "start_time": "2025-04-23T09:14:39.964276Z"
    }
   },
   "cell_type": "code",
   "source": "W2.grad",
   "id": "296ad9024331768d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan],\n",
       "        [nan]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Off Gradient Tracking",
   "id": "fa652f03317ae59c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### way-1",
   "id": "5df443377eb8afdb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:16:16.958151Z",
     "start_time": "2025-04-23T09:16:16.954462Z"
    }
   },
   "cell_type": "code",
   "source": "x = torch.tensor(3.0, requires_grad=True)",
   "id": "5921b535311bfd47",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:16:48.383355Z",
     "start_time": "2025-04-23T09:16:48.379132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    y = x**2"
   ],
   "id": "fe895a730b86a464",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:16:49.918017Z",
     "start_time": "2025-04-23T09:16:49.078242Z"
    }
   },
   "cell_type": "code",
   "source": "y.backward()",
   "id": "ef456727d524a4ce",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[43]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m y.backward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda3\\envs\\jh_env\\Lib\\site-packages\\torch\\_tensor.py:581\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    571\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    572\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    573\u001B[39m         Tensor.backward,\n\u001B[32m    574\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    579\u001B[39m         inputs=inputs,\n\u001B[32m    580\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m581\u001B[39m torch.autograd.backward(\n\u001B[32m    582\u001B[39m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs=inputs\n\u001B[32m    583\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda3\\envs\\jh_env\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    342\u001B[39m     retain_graph = create_graph\n\u001B[32m    344\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    345\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    346\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m347\u001B[39m _engine_run_backward(\n\u001B[32m    348\u001B[39m     tensors,\n\u001B[32m    349\u001B[39m     grad_tensors_,\n\u001B[32m    350\u001B[39m     retain_graph,\n\u001B[32m    351\u001B[39m     create_graph,\n\u001B[32m    352\u001B[39m     inputs,\n\u001B[32m    353\u001B[39m     allow_unreachable=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    354\u001B[39m     accumulate_grad=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    355\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda3\\envs\\jh_env\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    823\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    824\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m825\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable._execution_engine.run_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    826\u001B[39m         t_outputs, *args, **kwargs\n\u001B[32m    827\u001B[39m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    828\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    829\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mRuntimeError\u001B[39m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### way-2",
   "id": "5381da0e4e7e09a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:18:13.003426Z",
     "start_time": "2025-04-23T09:18:12.986721Z"
    }
   },
   "cell_type": "code",
   "source": "x = torch.tensor(3.0, requires_grad=True)",
   "id": "7a4bb85701bc3119",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:18:29.496436Z",
     "start_time": "2025-04-23T09:18:29.490669Z"
    }
   },
   "cell_type": "code",
   "source": "x.requires_grad_(False)",
   "id": "6aceac96ea6d6697",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:18:34.638512Z",
     "start_time": "2025-04-23T09:18:34.583277Z"
    }
   },
   "cell_type": "code",
   "source": "y.backward()",
   "id": "1f84dd2c3c292f2c",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[47]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m y.backward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda3\\envs\\jh_env\\Lib\\site-packages\\torch\\_tensor.py:581\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    571\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    572\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    573\u001B[39m         Tensor.backward,\n\u001B[32m    574\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    579\u001B[39m         inputs=inputs,\n\u001B[32m    580\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m581\u001B[39m torch.autograd.backward(\n\u001B[32m    582\u001B[39m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs=inputs\n\u001B[32m    583\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda3\\envs\\jh_env\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    342\u001B[39m     retain_graph = create_graph\n\u001B[32m    344\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    345\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    346\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m347\u001B[39m _engine_run_backward(\n\u001B[32m    348\u001B[39m     tensors,\n\u001B[32m    349\u001B[39m     grad_tensors_,\n\u001B[32m    350\u001B[39m     retain_graph,\n\u001B[32m    351\u001B[39m     create_graph,\n\u001B[32m    352\u001B[39m     inputs,\n\u001B[32m    353\u001B[39m     allow_unreachable=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    354\u001B[39m     accumulate_grad=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    355\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda3\\envs\\jh_env\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    823\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    824\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m825\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable._execution_engine.run_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    826\u001B[39m         t_outputs, *args, **kwargs\n\u001B[32m    827\u001B[39m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    828\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    829\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mRuntimeError\u001B[39m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# way-3",
   "id": "dc9a50c7384e95f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:19:27.331104Z",
     "start_time": "2025-04-23T09:19:27.322205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = x**2"
   ],
   "id": "6790799cd3134c3f",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:19:47.845362Z",
     "start_time": "2025-04-23T09:19:47.798054Z"
    }
   },
   "cell_type": "code",
   "source": "z = y.detach()",
   "id": "6ddc2769fe29df11",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:19:53.511208Z",
     "start_time": "2025-04-23T09:19:53.505834Z"
    }
   },
   "cell_type": "code",
   "source": "y.backward()",
   "id": "c904e017253b396b",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:19:58.540699Z",
     "start_time": "2025-04-23T09:19:58.485419Z"
    }
   },
   "cell_type": "code",
   "source": "z.backward()",
   "id": "5a09536fd2f12e1",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[51]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m z.backward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda3\\envs\\jh_env\\Lib\\site-packages\\torch\\_tensor.py:581\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    571\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    572\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    573\u001B[39m         Tensor.backward,\n\u001B[32m    574\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    579\u001B[39m         inputs=inputs,\n\u001B[32m    580\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m581\u001B[39m torch.autograd.backward(\n\u001B[32m    582\u001B[39m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs=inputs\n\u001B[32m    583\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda3\\envs\\jh_env\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    342\u001B[39m     retain_graph = create_graph\n\u001B[32m    344\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    345\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    346\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m347\u001B[39m _engine_run_backward(\n\u001B[32m    348\u001B[39m     tensors,\n\u001B[32m    349\u001B[39m     grad_tensors_,\n\u001B[32m    350\u001B[39m     retain_graph,\n\u001B[32m    351\u001B[39m     create_graph,\n\u001B[32m    352\u001B[39m     inputs,\n\u001B[32m    353\u001B[39m     allow_unreachable=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    354\u001B[39m     accumulate_grad=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    355\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda3\\envs\\jh_env\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    823\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    824\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m825\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable._execution_engine.run_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    826\u001B[39m         t_outputs, *args, **kwargs\n\u001B[32m    827\u001B[39m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    828\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    829\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mRuntimeError\u001B[39m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "47776c6a34fb68e8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
